{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the text across the applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import warnings\n",
    "\n",
    "# Ignore ipykernel warning\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning, module='ipykernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "applications = pd.read_parquet('../../Data/split_4_cleaned.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OpportunityId', 'ApplicationId', 'ExternalBriefDescription',\n",
       "       'ExternalDescription', 'Title', 'pass_first_step', 'Step_Category',\n",
       "       'Applicant_Job_Titles', 'Applicant_Job_Responsibilities',\n",
       "       'Applicant_Education', 'Applicant_Reported_Skills'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "applications.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column names\n",
    "applications.columns = ['opportunity_id', 'application_id', 'opportunity_brief_description',\n",
    "            'opportunity_description', 'opportunity_title', 'application_pass_first_step', 'application_step_category',\n",
    "            'application_job_titles', 'application_job_responsibilities',\n",
    "            'application_education', 'application_reported_skills']\n",
    "# Remove duplicates for job_descriptions\n",
    "original_descriptions = applications.opportunity_description.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are all lists of strings\n",
    "cols_not_to_concat = ['application_id', 'application_pass_first_step', 'application_step_category']\n",
    "application_cols = [col for col in applications.columns if 'application_' in col and col not in cols_not_to_concat]\n",
    "opportunity_cols = [col for col in applications.columns if 'opportunity_' in col and col != 'opportunity_id']\n",
    "\n",
    "applications['application_concat'] = applications[application_cols].astype(str).agg('--'.join,axis=1)\n",
    "\n",
    "applications['application_full_tokenized'] = applications['application_concat'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_cols.append(\"application_concat\")\n",
    "application_cols.append(\"application_full_tokenized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If column is object, it will become string\n",
    "for column in applications.columns:\n",
    "    if applications[column].dtype == object:\n",
    "        applications[column] = applications[column].astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22053 entries, 66159 to 88211\n",
      "Data columns (total 13 columns):\n",
      " #   Column                            Non-Null Count  Dtype \n",
      "---  ------                            --------------  ----- \n",
      " 0   opportunity_id                    22053 non-null  string\n",
      " 1   application_id                    22053 non-null  string\n",
      " 2   opportunity_brief_description     22053 non-null  string\n",
      " 3   opportunity_description           22053 non-null  string\n",
      " 4   opportunity_title                 22053 non-null  string\n",
      " 5   application_pass_first_step       22053 non-null  bool  \n",
      " 6   application_step_category         22053 non-null  int64 \n",
      " 7   application_job_titles            22053 non-null  string\n",
      " 8   application_job_responsibilities  22053 non-null  string\n",
      " 9   application_education             22053 non-null  string\n",
      " 10  application_reported_skills       22053 non-null  string\n",
      " 11  application_concat                22053 non-null  string\n",
      " 12  application_full_tokenized        22053 non-null  string\n",
      "dtypes: bool(1), int64(1), string(11)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "applications.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['opportunity_id', 'application_id', 'opportunity_brief_description',\n",
       "       'opportunity_description', 'opportunity_title',\n",
       "       'application_pass_first_step', 'application_step_category',\n",
       "       'application_job_titles', 'application_job_responsibilities',\n",
       "       'application_education', 'application_reported_skills',\n",
       "       'application_concat', 'application_full_tokenized'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "applications.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_preprocess = ['opportunity_brief_description', 'opportunity_description', 'opportunity_title',\n",
    "                        'application_job_titles', 'application_job_responsibilities',\n",
    "                        'application_concat', 'application_full_tokenized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on opportunity_brief_description\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/danmarino/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/danmarino/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on opportunity_description\n",
      "working on opportunity_title\n",
      "working on application_job_titles\n",
      "working on application_job_responsibilities\n",
      "working on application_concat\n",
      "working on application_full_tokenized\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\b\\w+\\b')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def strip_html_tags(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    text = re.sub(html_pattern, '', text)\n",
    "    return text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Strip HTML tags and convert to lowercase\n",
    "    text = strip_html_tags(text).lower()\n",
    "    \n",
    "    # Remove unwanted strings using compiled regex pattern\n",
    "    # This changed\n",
    "    unwanted_strings = ['sign on bonus', 'sign bonus',\n",
    "                         'full time', 'part time',\n",
    "                         'day shift', 'night shift', 'second shift',\n",
    "                         'third shift', 'first shift', 'none', 'nbsp', 'amp']\n",
    "    unwanted_pattern = re.compile('|'.join(map(re.escape, unwanted_strings)))\n",
    "    text = re.sub(unwanted_pattern, '', text)\n",
    "\n",
    "    # Tokenize the text and remove stopwords while lemmatizing\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokenizer.tokenize(text) if token not in stop_words]\n",
    "\n",
    "    # Join the tokens back into a single string\n",
    "    text = ' '.join(tokens)\n",
    "\n",
    "    return text\n",
    "\n",
    "for column in columns_to_preprocess:\n",
    "    print(f\"working on {column}\")\n",
    "    applications[column] = applications[column].apply(preprocess_text)\n",
    "\n",
    "applications = applications.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: application_job_titles\n",
      "Unique data types: {<class 'str'>}\n",
      "Column: application_job_responsibilities\n",
      "Unique data types: {<class 'str'>}\n",
      "Column: application_education\n",
      "Unique data types: {<class 'str'>}\n",
      "Column: application_reported_skills\n",
      "Unique data types: {<class 'str'>}\n",
      "Column: application_concat\n",
      "Unique data types: {<class 'str'>}\n",
      "Column: application_full_tokenized\n",
      "Unique data types: {<class 'str'>}\n"
     ]
    }
   ],
   "source": [
    "# Re-run the test code to see if the data types have changed\n",
    "for col in application_cols:\n",
    "    print(\"Column:\", col)\n",
    "    dtypes_of_items = set()  # Use a set to store unique data types\n",
    "    for cell in applications[col]:\n",
    "        for item in cell:\n",
    "            if item is not None:\n",
    "                dtypes_of_items.add(type(item))\n",
    "            else:\n",
    "                dtypes_of_items.add(type(None))\n",
    "    print(\"Unique data types:\", dtypes_of_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Everything is a string, which is essential for compatability with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opportunity_id</th>\n",
       "      <th>application_id</th>\n",
       "      <th>opportunity_brief_description</th>\n",
       "      <th>opportunity_description</th>\n",
       "      <th>opportunity_title</th>\n",
       "      <th>application_pass_first_step</th>\n",
       "      <th>application_step_category</th>\n",
       "      <th>application_job_titles</th>\n",
       "      <th>application_job_responsibilities</th>\n",
       "      <th>application_education</th>\n",
       "      <th>application_reported_skills</th>\n",
       "      <th>application_concat</th>\n",
       "      <th>application_full_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82227</th>\n",
       "      <td>1C4XzVi21UWFqTKe+nZ7Sw==</td>\n",
       "      <td>Fx2VS8W+2U6hpAX/a8ja9Q==</td>\n",
       "      <td>15 00 per hour orkin purpose help protect worl...</td>\n",
       "      <td>15 00 per hour orkin purpose help protect worl...</td>\n",
       "      <td>service technician train</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>student loan advocate lead generator appointme...</td>\n",
       "      <td>assist student grievance regarding student loa...</td>\n",
       "      <td>Associates</td>\n",
       "      <td>Microsoft Office++Customer Service++Financial ...</td>\n",
       "      <td>student loan advocate lead generator appointme...</td>\n",
       "      <td>student loan advocate lead generator appointme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85580</th>\n",
       "      <td>+0cRKl9xvkGTQq4D8IwnAQ==</td>\n",
       "      <td>b3CzgKctxECMigmjIvtW+A==</td>\n",
       "      <td>first year earnings opportunity 40 000 50 000 ...</td>\n",
       "      <td>first year earnings opportunity 40 000 50 000 ...</td>\n",
       "      <td>service technician train</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>production</td>\n",
       "      <td>make refrigerator</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>production make refrigerator</td>\n",
       "      <td>production make refrigerator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69959</th>\n",
       "      <td>CfU7r5cLfEua4pLMBVkS5Q==</td>\n",
       "      <td>dNp19WQwz0G3jYvHsusHNQ==</td>\n",
       "      <td>orkin purpose help protect world live work pla...</td>\n",
       "      <td>orkin purpose help protect world live work pla...</td>\n",
       "      <td>service technician train</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>general worker</td>\n",
       "      <td>operated water extraction carpet cleaning truck</td>\n",
       "      <td>1 year</td>\n",
       "      <td></td>\n",
       "      <td>general worker operated water extraction carpe...</td>\n",
       "      <td>general worker operated water extraction carpe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 opportunity_id            application_id  \\\n",
       "82227  1C4XzVi21UWFqTKe+nZ7Sw==  Fx2VS8W+2U6hpAX/a8ja9Q==   \n",
       "85580  +0cRKl9xvkGTQq4D8IwnAQ==  b3CzgKctxECMigmjIvtW+A==   \n",
       "69959  CfU7r5cLfEua4pLMBVkS5Q==  dNp19WQwz0G3jYvHsusHNQ==   \n",
       "\n",
       "                           opportunity_brief_description  \\\n",
       "82227  15 00 per hour orkin purpose help protect worl...   \n",
       "85580  first year earnings opportunity 40 000 50 000 ...   \n",
       "69959  orkin purpose help protect world live work pla...   \n",
       "\n",
       "                                 opportunity_description  \\\n",
       "82227  15 00 per hour orkin purpose help protect worl...   \n",
       "85580  first year earnings opportunity 40 000 50 000 ...   \n",
       "69959  orkin purpose help protect world live work pla...   \n",
       "\n",
       "              opportunity_title application_pass_first_step  \\\n",
       "82227  service technician train                       False   \n",
       "85580  service technician train                        True   \n",
       "69959  service technician train                       False   \n",
       "\n",
       "      application_step_category  \\\n",
       "82227                         0   \n",
       "85580                         0   \n",
       "69959                         0   \n",
       "\n",
       "                                  application_job_titles  \\\n",
       "82227  student loan advocate lead generator appointme...   \n",
       "85580                                         production   \n",
       "69959                                     general worker   \n",
       "\n",
       "                        application_job_responsibilities  \\\n",
       "82227  assist student grievance regarding student loa...   \n",
       "85580                                  make refrigerator   \n",
       "69959    operated water extraction carpet cleaning truck   \n",
       "\n",
       "      application_education  \\\n",
       "82227            Associates   \n",
       "85580                         \n",
       "69959                1 year   \n",
       "\n",
       "                             application_reported_skills  \\\n",
       "82227  Microsoft Office++Customer Service++Financial ...   \n",
       "85580                                                      \n",
       "69959                                                      \n",
       "\n",
       "                                      application_concat  \\\n",
       "82227  student loan advocate lead generator appointme...   \n",
       "85580                       production make refrigerator   \n",
       "69959  general worker operated water extraction carpe...   \n",
       "\n",
       "                              application_full_tokenized  \n",
       "82227  student loan advocate lead generator appointme...  \n",
       "85580                       production make refrigerator  \n",
       "69959  general worker operated water extraction carpe...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "applications.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We want zero NoneType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "applications.to_parquet('../../Data/split_4_preprocessed.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
